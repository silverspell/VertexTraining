{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a55c457",
   "metadata": {},
   "source": [
    "# Golden Dataset & RAG Benchmarking (Jupyter)\n",
    "\n",
    "Bu notebook, bir RAG sisteminin **ölçülebilir** şekilde iyileştirilmesi için gereken akışı gösterir:\n",
    "\n",
    "1) **Golden dataset** (soru + ground-truth cevap + beklenen kaynaklar)  \n",
    "2) **Chunking** (baseline vs iyileştirilmiş)  \n",
    "3) **Retrieval benchmarking**: Recall@k, MRR, nDCG  \n",
    "4) (Opsiyonel) **Faithfulness / Answer Relevance** (LLM-as-a-judge veya kural-tabanlı proxy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33029c7",
   "metadata": {},
   "source": [
    "## 0) Kurulum\n",
    "\n",
    "- Bu demo **LLM zorunlu değil**: retrieval metrikleri tamamen offline ölçülür.\n",
    "- LLM tabanlı metrikler (faithfulness/relevance) **opsiyonel** ve notebook içinde yorum satırında.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "676c9fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install pandas numpy scikit-learn rank-bm25 sentence-transformers faiss-cpu google-cloud-aiplatform google-genai pydantic\n",
    "\n",
    "\n",
    "# (Opsiyonel) RAGAS:\n",
    "# %pip -q install ragas\n",
    "\n",
    "# Kurulum sonrası kernel restart gerekebilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80394077",
   "metadata": {},
   "source": [
    "## 1) Mini Corpus (Demo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71458aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Vertex AI Studio</td>\n",
       "      <td>Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Document AI Form Extractor</td>\n",
       "      <td>Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir. HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>RAG Optimizasyonu</td>\n",
       "      <td>RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id                       title  \\\n",
       "0     D1            Vertex AI Studio   \n",
       "1     D2  Document AI Form Extractor   \n",
       "2     D3           RAG Optimizasyonu   \n",
       "\n",
       "                                                                                                                                                                                                                                                            text  \n",
       "0                                                                              Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.  \n",
       "1  Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir. HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.  \n",
       "2                                            RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('max_colwidth', 400)\n",
    "\n",
    "\n",
    "\n",
    "docs = [\n",
    "    {\n",
    "        \"doc_id\": \"D1\",\n",
    "        \"title\": \"Vertex AI Studio\",\n",
    "        \"text\": (\n",
    "            \"Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. \"\n",
    "            \"Language, Vision ve Speech gibi modlarda çalışabilir. \"\n",
    "            \"Parametreler: temperature, top-p, max_output_tokens.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": \"D2\",\n",
    "        \"title\": \"Document AI Form Extractor\",\n",
    "        \"text\": (\n",
    "            \"Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. \"\n",
    "            \"Form Extractor key-value çiftlerini yakalamaya odaklanır. \"\n",
    "            \"Invoice Processor gibi specialized processorlar entities döndürebilir. \"\n",
    "            \"HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": \"D3\",\n",
    "        \"title\": \"RAG Optimizasyonu\",\n",
    "        \"text\": (\n",
    "            \"RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. \"\n",
    "            \"Chunking stratejileri (recursive, semantic) sonucu etkiler. \"\n",
    "            \"Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "df_docs = pd.DataFrame(docs)\n",
    "df_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d922f5",
   "metadata": {},
   "source": [
    "## 2) Chunking\n",
    "\n",
    "İki basit chunker:\n",
    "- **Baseline**: sabit uzunluk (char bazlı)\n",
    "- **Improved**: cümle tabanlı (basit semantic-ish)\n",
    "\n",
    "Gerçek projede: doc-type bazlı splitter / recursive / semantic splitter kullanılır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb5395ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline chunks: 6\n",
      "improved chunks: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Vertex AI Studio</td>\n",
       "      <td>D1_C1</td>\n",
       "      <td>Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Document AI Form Extractor</td>\n",
       "      <td>D2_C1</td>\n",
       "      <td>Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2</td>\n",
       "      <td>Document AI Form Extractor</td>\n",
       "      <td>D2_C2</td>\n",
       "      <td>HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3</td>\n",
       "      <td>RAG Optimizasyonu</td>\n",
       "      <td>D3_C1</td>\n",
       "      <td>RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id                       title chunk_id  \\\n",
       "0     D1            Vertex AI Studio    D1_C1   \n",
       "1     D2  Document AI Form Extractor    D2_C1   \n",
       "2     D2  Document AI Form Extractor    D2_C2   \n",
       "3     D3           RAG Optimizasyonu    D3_C1   \n",
       "\n",
       "                                                                                                                                                                                                                  text  \n",
       "0                                    Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.  \n",
       "1                     Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir.  \n",
       "2                                                                                                                                                         HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.  \n",
       "3  RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "def chunk_fixed(text: str, chunk_size: int = 200, overlap: int = 30) -> List[str]:\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        chunks.append(text[i:i+chunk_size].strip())\n",
    "        i += max(1, chunk_size - overlap)\n",
    "    return [c for c in chunks if c]\n",
    "\n",
    "def chunk_sentences(text: str, max_chars: int = 240) -> List[str]:\n",
    "    sents = [s.strip() for s in re.split(r\"(?<=[.!?])\\s+\", text) if s.strip()]\n",
    "    chunks, buf = [], \"\"\n",
    "    for s in sents:\n",
    "        if len(buf) + len(s) + 1 <= max_chars:\n",
    "            buf = (buf + \" \" + s).strip()\n",
    "        else:\n",
    "            if buf:\n",
    "                chunks.append(buf)\n",
    "            buf = s\n",
    "    if buf:\n",
    "        chunks.append(buf)\n",
    "    return chunks\n",
    "\n",
    "def build_chunks(docs: List[Dict], mode: str = \"baseline\") -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for d in docs:\n",
    "        chunks = chunk_fixed(d[\"text\"]) if mode == \"baseline\" else chunk_sentences(d[\"text\"])\n",
    "        for j, ch in enumerate(chunks):\n",
    "            rows.append({\n",
    "                \"doc_id\": d[\"doc_id\"],\n",
    "                \"title\": d[\"title\"],\n",
    "                \"chunk_id\": f\"{d['doc_id']}_C{j+1}\",\n",
    "                \"text\": ch\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_chunks_baseline = build_chunks(docs, mode=\"baseline\")\n",
    "df_chunks_improved = build_chunks(docs, mode=\"improved\")\n",
    "\n",
    "print(\"baseline chunks:\", len(df_chunks_baseline))\n",
    "print(\"improved chunks:\", len(df_chunks_improved))\n",
    "df_chunks_improved.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c3b73",
   "metadata": {},
   "source": [
    "## 3) Sparse Retrieval (BM25) — Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01ffda87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D3</td>\n",
       "      <td>RAG Optimizasyonu</td>\n",
       "      <td>D3_C1</td>\n",
       "      <td>RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.</td>\n",
       "      <td>3.782560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Document AI Form Extractor</td>\n",
       "      <td>D2_C2</td>\n",
       "      <td>HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.</td>\n",
       "      <td>0.263349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1</td>\n",
       "      <td>Vertex AI Studio</td>\n",
       "      <td>D1_C1</td>\n",
       "      <td>Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.</td>\n",
       "      <td>0.190119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2</td>\n",
       "      <td>Document AI Form Extractor</td>\n",
       "      <td>D2_C1</td>\n",
       "      <td>Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id                       title chunk_id  \\\n",
       "0     D3           RAG Optimizasyonu    D3_C1   \n",
       "1     D2  Document AI Form Extractor    D2_C2   \n",
       "2     D1            Vertex AI Studio    D1_C1   \n",
       "3     D2  Document AI Form Extractor    D2_C1   \n",
       "\n",
       "                                                                                                                                                                                                                  text  \\\n",
       "0  RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.   \n",
       "1                                                                                                                                                         HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.   \n",
       "2                                    Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.   \n",
       "3                     Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir.   \n",
       "\n",
       "      score  \n",
       "0  3.782560  \n",
       "1  0.263349  \n",
       "2  0.190119  \n",
       "3  0.000000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return re.findall(r\"[\\wğüşöçıİĞÜŞÖÇ]+\", text.lower())\n",
    "\n",
    "def bm25_index(chunks_df: pd.DataFrame):\n",
    "    corpus_tokens = [tokenize(t) for t in chunks_df[\"text\"].tolist()]\n",
    "    bm25 = BM25Okapi(corpus_tokens)\n",
    "    return bm25\n",
    "\n",
    "def bm25_search(bm25, chunks_df: pd.DataFrame, query: str, k: int = 5):\n",
    "    scores = bm25.get_scores(tokenize(query))\n",
    "    top_idx = np.argsort(scores)[::-1][:k]\n",
    "    out = chunks_df.iloc[top_idx].copy()\n",
    "    out[\"score\"] = scores[top_idx]\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "bm25_b = bm25_index(df_chunks_baseline)\n",
    "bm25_i = bm25_index(df_chunks_improved)\n",
    "\n",
    "bm25_search(bm25_i, df_chunks_improved, \"RAG kalitesini ölçmek için hangi retrieval metrikleri kullanılır?\", k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c0c087",
   "metadata": {},
   "source": [
    "## 4) (Opsiyonel) Dense Retrieval\n",
    "\n",
    "Daha gerçekçi RAG için sentence-transformers + cosine similarity kullanılır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae73a5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XLMRobertaModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D3</td>\n",
       "      <td>RAG Optimizasyonu</td>\n",
       "      <td>D3_C1</td>\n",
       "      <td>RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.</td>\n",
       "      <td>0.713404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Document AI Form Extractor</td>\n",
       "      <td>D2_C2</td>\n",
       "      <td>HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.</td>\n",
       "      <td>0.446019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2</td>\n",
       "      <td>Document AI Form Extractor</td>\n",
       "      <td>D2_C1</td>\n",
       "      <td>Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir.</td>\n",
       "      <td>0.303907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D1</td>\n",
       "      <td>Vertex AI Studio</td>\n",
       "      <td>D1_C1</td>\n",
       "      <td>Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.</td>\n",
       "      <td>0.301792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id                       title chunk_id  \\\n",
       "0     D3           RAG Optimizasyonu    D3_C1   \n",
       "1     D2  Document AI Form Extractor    D2_C2   \n",
       "2     D2  Document AI Form Extractor    D2_C1   \n",
       "3     D1            Vertex AI Studio    D1_C1   \n",
       "\n",
       "                                                                                                                                                                                                                  text  \\\n",
       "0  RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.   \n",
       "1                                                                                                                                                         HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.   \n",
       "2                     Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir.   \n",
       "3                                    Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.   \n",
       "\n",
       "      score  \n",
       "0  0.713404  \n",
       "1  0.446019  \n",
       "2  0.303907  \n",
       "3  0.301792  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "def dense_index(chunks_df: pd.DataFrame):\n",
    "    X = embedder.encode(chunks_df[\"text\"].tolist(), normalize_embeddings=True)\n",
    "    return X\n",
    "\n",
    "def dense_search(X, chunks_df: pd.DataFrame, query: str, k: int = 5):\n",
    "    q = embedder.encode([query], normalize_embeddings=True)\n",
    "    sims = cosine_similarity(q, X)[0]\n",
    "    top_idx = np.argsort(sims)[::-1][:k]\n",
    "    out = chunks_df.iloc[top_idx].copy()\n",
    "    out[\"score\"] = sims[top_idx]\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "X_i = dense_index(df_chunks_improved)\n",
    "dense_i = dense_search(X_i, df_chunks_improved, \"RAG kalitesini ölçmek için hangi retrieval metrikleri kullanılır?\", k=5)\n",
    "display(dense_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04a0f3c",
   "metadata": {},
   "source": [
    "## 5) Golden Dataset\n",
    "\n",
    "Önerilen alanlar:\n",
    "- `query`: soru\n",
    "- `answer`: ground-truth kısa cevap (insan doğrulamalı)\n",
    "- `relevant_doc_ids`: doğru doküman(lar) veya chunk id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "929fa70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>relevant_doc_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>RAG kalitesini ölçmek için hangi retrieval metrikleri kullanılır?</td>\n",
       "      <td>Recall@k, MRR ve nDCG gibi retrieval metrikleri kullanılır.</td>\n",
       "      <td>[D3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>Document AI'da HITL ne işe yarar?</td>\n",
       "      <td>Human-in-the-loop (HITL), insan onayıyla doğruluğu artırmak için kullanılır.</td>\n",
       "      <td>[D2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>Vertex AI Studio hangi amaçla kullanılır ve hangi parametreler test edilir?</td>\n",
       "      <td>Prompt denemeleri/model testleri için; temperature, top-p, max_output_tokens gibi parametreler test edilir.</td>\n",
       "      <td>[D1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  \\\n",
       "0  Q1   \n",
       "1  Q2   \n",
       "2  Q3   \n",
       "\n",
       "                                                                         query  \\\n",
       "0            RAG kalitesini ölçmek için hangi retrieval metrikleri kullanılır?   \n",
       "1                                            Document AI'da HITL ne işe yarar?   \n",
       "2  Vertex AI Studio hangi amaçla kullanılır ve hangi parametreler test edilir?   \n",
       "\n",
       "                                                                                                        answer  \\\n",
       "0                                                  Recall@k, MRR ve nDCG gibi retrieval metrikleri kullanılır.   \n",
       "1                                 Human-in-the-loop (HITL), insan onayıyla doğruluğu artırmak için kullanılır.   \n",
       "2  Prompt denemeleri/model testleri için; temperature, top-p, max_output_tokens gibi parametreler test edilir.   \n",
       "\n",
       "  relevant_doc_ids  \n",
       "0             [D3]  \n",
       "1             [D2]  \n",
       "2             [D1]  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden = [\n",
    "    {\n",
    "        \"qid\": \"Q1\",\n",
    "        \"query\": \"RAG kalitesini ölçmek için hangi retrieval metrikleri kullanılır?\",\n",
    "        \"answer\": \"Recall@k, MRR ve nDCG gibi retrieval metrikleri kullanılır.\",\n",
    "        \"relevant_doc_ids\": [\"D3\"],\n",
    "    },\n",
    "    {\n",
    "        \"qid\": \"Q2\",\n",
    "        \"query\": \"Document AI'da HITL ne işe yarar?\",\n",
    "        \"answer\": \"Human-in-the-loop (HITL), insan onayıyla doğruluğu artırmak için kullanılır.\",\n",
    "        \"relevant_doc_ids\": [\"D2\"],\n",
    "    },\n",
    "    {\n",
    "        \"qid\": \"Q3\",\n",
    "        \"query\": \"Vertex AI Studio hangi amaçla kullanılır ve hangi parametreler test edilir?\",\n",
    "        \"answer\": \"Prompt denemeleri/model testleri için; temperature, top-p, max_output_tokens gibi parametreler test edilir.\",\n",
    "        \"relevant_doc_ids\": [\"D1\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "df_golden = pd.DataFrame(golden)\n",
    "df_golden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7af8417",
   "metadata": {},
   "source": [
    "## 6) Retrieval Benchmarking — Recall@k, MRR, nDCG\n",
    "\n",
    "Demo: doc_id üstünden ölçüyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Set\n",
    "\n",
    "def dcg(rels: List[int]) -> float:\n",
    "    return sum((2**rel - 1) / math.log2(i+2) for i, rel in enumerate(rels))\n",
    "\n",
    "def ndcg_at_k(retrieved_doc_ids: List[str], relevant: Set[str], k: int) -> float:\n",
    "    rels = [1 if d in relevant else 0 for d in retrieved_doc_ids[:k]]\n",
    "    ideal = sorted(rels, reverse=True)\n",
    "    denom = dcg(ideal)\n",
    "    return dcg(rels) / denom if denom > 0 else 0.0\n",
    "\n",
    "def mrr_at_k(retrieved_doc_ids: List[str], relevant: Set[str], k: int) -> float:\n",
    "    for i, d in enumerate(retrieved_doc_ids[:k]):\n",
    "        if d in relevant:\n",
    "            return 1.0 / (i+1)\n",
    "    return 0.0\n",
    "\n",
    "def recall_at_k(retrieved_doc_ids: List[str], relevant: Set[str], k: int) -> float:\n",
    "    got = set(retrieved_doc_ids[:k]) & relevant\n",
    "    return len(got) / len(relevant) if relevant else 0.0\n",
    "\n",
    "def eval_retrieval(chunks_df: pd.DataFrame, bm25, golden_df: pd.DataFrame, k: int = 5) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, g in golden_df.iterrows():\n",
    "        res = bm25_search(bm25, chunks_df, g[\"query\"], k=k)\n",
    "        retrieved_docs = res[\"doc_id\"].tolist()\n",
    "        relevant = set(g[\"relevant_doc_ids\"])\n",
    "        rows.append({\n",
    "            \"qid\": g[\"qid\"],\n",
    "            \"recall@k\": recall_at_k(retrieved_docs, relevant, k),\n",
    "            \"mrr@k\": mrr_at_k(retrieved_docs, relevant, k),\n",
    "            \"ndcg@k\": ndcg_at_k(retrieved_docs, relevant, k),\n",
    "            \"top_docs\": retrieved_docs[:k],\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "report_baseline = eval_retrieval(df_chunks_baseline, bm25_b, df_golden, k=5)\n",
    "report_improved = eval_retrieval(df_chunks_improved, bm25_i, df_golden, k=5)\n",
    "\n",
    "print(\"Baseline:\")\n",
    "display(report_baseline)\n",
    "\n",
    "print(\"Improved:\")\n",
    "display(report_improved)\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"setup\": \"baseline_bm25\", \"recall@5\": report_baseline[\"recall@k\"].mean(), \"mrr@5\": report_baseline[\"mrr@k\"].mean(), \"ndcg@5\": report_baseline[\"ndcg@k\"].mean()},\n",
    "    {\"setup\": \"improved_bm25\", \"recall@5\": report_improved[\"recall@k\"].mean(), \"mrr@5\": report_improved[\"mrr@k\"].mean(), \"ndcg@5\": report_improved[\"ndcg@k\"].mean()},\n",
    "])\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1252d2",
   "metadata": {},
   "source": [
    "## 7) Debug View (Hata Analizi)\n",
    "\n",
    "“Kaçırdığımız” soruları tek tek incelemek en büyük hızlandırıcı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c1dfaf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Vertex AI Studio hangi amaçla kullanılır ve hangi parametreler test edilir?\n",
      "GT docs: ['D1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Vertex AI Studio</td>\n",
       "      <td>D1_C1</td>\n",
       "      <td>3.624454</td>\n",
       "      <td>Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D3</td>\n",
       "      <td>RAG Optimizasyonu</td>\n",
       "      <td>D3_C1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2</td>\n",
       "      <td>Document AI Form Extractor</td>\n",
       "      <td>D2_C2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2</td>\n",
       "      <td>Document AI Form Extractor</td>\n",
       "      <td>D2_C1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id                       title chunk_id     score  \\\n",
       "0     D1            Vertex AI Studio    D1_C1  3.624454   \n",
       "1     D3           RAG Optimizasyonu    D3_C1  0.000000   \n",
       "2     D2  Document AI Form Extractor    D2_C2  0.000000   \n",
       "3     D2  Document AI Form Extractor    D2_C1  0.000000   \n",
       "\n",
       "                                                                                                                                                                                                                  text  \n",
       "0                                    Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır. Language, Vision ve Speech gibi modlarda çalışabilir. Parametreler: temperature, top-p, max_output_tokens.  \n",
       "1  RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG. Chunking stratejileri (recursive, semantic) sonucu etkiler. Hybrid search: BM25 + vektör arama. Re-ranking en alakalı sonuçları yukarı taşır.  \n",
       "2                                                                                                                                                         HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.  \n",
       "3                     Document AI, PDF gibi belgelerden yapılandırılmış veri çıkarır. Form Extractor key-value çiftlerini yakalamaya odaklanır. Invoice Processor gibi specialized processorlar entities döndürebilir.  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug_one(qid: str, chunks_df: pd.DataFrame, bm25, golden_df: pd.DataFrame, k: int = 5):\n",
    "    g = golden_df[golden_df[\"qid\"] == qid].iloc[0]\n",
    "    res = bm25_search(bm25, chunks_df, g[\"query\"], k=k)\n",
    "    print(\"Q:\", g[\"query\"])\n",
    "    print(\"GT docs:\", g[\"relevant_doc_ids\"])\n",
    "    return res[[\"doc_id\",\"title\",\"chunk_id\",\"score\",\"text\"]]\n",
    "\n",
    "debug_one(\"Q3\", df_chunks_improved, bm25_i, df_golden, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d1d0c",
   "metadata": {},
   "source": [
    "## 8) LLM-as-a-Judge (Gemini / Vertex AI) — Faithfulness & Answer Relevance (Opsiyonel)\n",
    "\n",
    "Bu bölüm **opsiyonel** ve ücret doğurur.\n",
    "\n",
    "Amaç:\n",
    "- **Answer Relevance**: Cevap, soruyu gerçekten yanıtlıyor mu?\n",
    "- **Faithfulness**: Cevaptaki iddialar, verilen **context** tarafından destekleniyor mu? (grounding)\n",
    "\n",
    "Çıktı: her metrik için 0.0–1.0 arası skor + kısa gerekçe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "727c14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Judge konfig\n",
    "project_id  = \"vertextraining-486212\"\n",
    "region      = \"europe-west2\"\n",
    "judge_model = \"gemini-2.5-flash\"\n",
    "\n",
    "judge_temperature = 0.0\n",
    "judge_max_output_tokens = 1024\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1644d5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Judge model hazır: gemini-2.5-flash | region: europe-west2\n"
     ]
    }
   ],
   "source": [
    "from vertexai import init\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig, SafetySetting, HarmBlockThreshold, HarmCategory\n",
    "from google import genai\n",
    "\n",
    "init(project=project_id, location=region)\n",
    "\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=project_id,\n",
    "    location=region,\n",
    ")\n",
    "\n",
    "print(\"✅ Judge model hazır:\", judge_model, \"| region:\", region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0221ce",
   "metadata": {},
   "source": [
    "## Judge Fonksiyonları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "75d7c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class JudgeOut(BaseModel):\n",
    "    score: float = Field(..., ge=0.0, le=1.0)\n",
    "    rationale: str = Field(..., max_length=1024)\n",
    "\n",
    "\n",
    "def call_judge(prompt: str, *, model=judge_model) -> dict:\n",
    "    resp = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=prompt,\n",
    "        config={\n",
    "            \"temperature\": 0.0,\n",
    "            \"top_p\": 1.0,\n",
    "            #\"max_output_tokens\": judge_max_output_tokens,\n",
    "            # Structured output:\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_schema\": JudgeOut,\n",
    "            # Safety settings (isteğe göre gevşet):\n",
    "            \"safety_settings\": [\n",
    "               {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
    "               {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
    "               {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
    "               {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
    "         ],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    cand = (getattr(resp, \"candidates\", None) or [None])[0]\n",
    "    finish = getattr(cand, \"finish_reason\", None)\n",
    "\n",
    "    parsed = getattr(resp, \"parsed\", None)\n",
    "    if parsed is not None:\n",
    "        return parsed.model_dump() if hasattr(parsed, \"model_dump\") else dict(parsed)\n",
    "\n",
    "    # Buraya düştüyse: muhtemelen blok/boş\n",
    "    return {\n",
    "        \"score\": 0.0,\n",
    "        \"rationale\": f\"blocked_or_empty (finish_reason={finish})\",\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def judge_relevance_tr(question: str, answer: str) -> dict:\n",
    "    prompt = f\"\"\"\n",
    "Sen bir değerlendirme asistanısın.\n",
    "Görev: Aşağıdaki Soru ve Cevap için \"Cevap Uygunluğu\" puanı ver.\n",
    "\n",
    "Puanlama:\n",
    "- 1.0: Cevap soruyu doğrudan ve yeterince yanıtlıyor.\n",
    "- 0.5: Kısmen yanıtlıyor; eksik/muğlak.\n",
    "- 0.0: Alakasız; soruyu yanıtlamıyor.\n",
    "\n",
    "Soru: {question}\n",
    "Cevap: {answer}\n",
    "\n",
    "Sadece JSON döndür.\n",
    "\"\"\"\n",
    "    return call_judge(prompt)\n",
    "\n",
    "def judge_faithfulness_tr(question: str, answer: str, contexts: list[str]) -> dict:\n",
    "    ctx = \"\\n\\n\".join([f\"[C{i+1}] {c}\" for i, c in enumerate(contexts)])\n",
    "    prompt = f\"\"\"\n",
    "Sen bir değerlendirme asistanısın.\n",
    "Görev: Cevabın, aşağıdaki Bağlam tarafından ne ölçüde desteklendiğini puanla.\n",
    "\n",
    "Puanlama:\n",
    "- 1.0: Cevabın ana noktaları bağlamda açıkça destekleniyor.\n",
    "- 0.5: Kısmen destekleniyor; bazı kısımlar belirsiz/eksik.\n",
    "- 0.0: Büyük ölçüde bağlamda yok veya bağlamla uyuşmuyor.\n",
    "\n",
    "Kural: Yalnızca verilen bağlama dayan.\n",
    "\n",
    "Soru: {question}\n",
    "\n",
    "Bağlam:\n",
    "{ctx}\n",
    "\n",
    "Cevap: {answer}\n",
    "\n",
    "Sadece JSON döndür.\n",
    "\"\"\"\n",
    "    return call_judge(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9424cd1",
   "metadata": {},
   "source": [
    "### RAG cevaplarını bağlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "686a100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kendi sistem çıktını buraya koy (qid -> answer)\n",
    "rag_answers = {\n",
    "    \"Q1\": \"RAG kalitesini ölçmek için retrieval metrikleri: Recall@k, MRR, nDCG.\",\n",
    "    \"Q2\": \"HITL (Human-in-the-loop) doğruluğu artırmak için kullanılır.\",\n",
    "    \"Q3\": \"Vertex AI Studio, prompt denemeleri ve model testleri için kullanılır.\",\n",
    "}\n",
    "\n",
    "# Demo için: eksikse golden answer'ı kullan\n",
    "use_golden_if_missing = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986ecdf",
   "metadata": {},
   "source": [
    "### Judge evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4d51571c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>relevance_rationale</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>faithfulness_rationale</th>\n",
       "      <th>ctx_doc_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cevap, RAG kalitesini ölçmek için kullanılan temel retrieval metriklerini (Recall@k, MRR, nDCG) doğrudan ve doğru bir şekilde listelemiştir. Soruya tam ve yeterli bir yanıt vermektedir.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cevap, RAG kalitesini ölçmek için kullanılan retrieval metriklerini (Recall@k, MRR, nDCG) doğrudan ve eksiksiz bir şekilde Bağlam [C1]'den almaktadır. Bağlam, cevabın ana noktalarını açıkça desteklemektedir.</td>\n",
       "      <td>[D3, D2, D1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cevap, HITL'nin Document AI'daki temel amacını (doğruluğu artırma) doğrudan ve doğru bir şekilde belirtmektedir. Soruyu yeterince yanıtlamaktadır.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Cevap, HITL'nin doğruluğu artırmak için kullanıldığı bilgisini doğrudan Bağlam [C1]'den almaktadır. Ancak, soru HITL'nin 'Document AI'da' ne işe yaradığını sormaktadır. Bağlam, Document AI'dan [C2] bahsetse de, HITL'nin bu özel bağlamda kullanıldığına dair açık bir bağlantı kurmamaktadır. Bu nedenle, cevabın ana noktası desteklenirken, sorunun spesifik kapsamı (Document AI) bağlamda tam olarak...</td>\n",
       "      <td>[D2, D2, D3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Cevap, Vertex AI Studio'nun amacını (prompt denemeleri ve model testleri) doğru bir şekilde belirtiyor ancak hangi parametrelerin test edildiği sorusunu yanıtlamıyor. Bu nedenle kısmen doğru ve eksiktir.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Cevap, Vertex AI Studio'nun amacını (prompt denemeleri ve model testleri) Bağlam [C1]'den doğru bir şekilde belirtmektedir. Ancak, sorunun ikinci kısmı olan 'hangi parametreler test edilir?' sorusunu yanıtlamamıştır, oysa bu bilgi de Bağlam [C1]'de mevcuttur (temperature, top-p, max_output_tokens).</td>\n",
       "      <td>[D1, D3, D2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  answer_relevance  \\\n",
       "0  Q1               1.0   \n",
       "1  Q2               1.0   \n",
       "2  Q3               0.5   \n",
       "\n",
       "                                                                                                                                                                                           relevance_rationale  \\\n",
       "0                    Cevap, RAG kalitesini ölçmek için kullanılan temel retrieval metriklerini (Recall@k, MRR, nDCG) doğrudan ve doğru bir şekilde listelemiştir. Soruya tam ve yeterli bir yanıt vermektedir.   \n",
       "1                                                           Cevap, HITL'nin Document AI'daki temel amacını (doğruluğu artırma) doğrudan ve doğru bir şekilde belirtmektedir. Soruyu yeterince yanıtlamaktadır.   \n",
       "2  Cevap, Vertex AI Studio'nun amacını (prompt denemeleri ve model testleri) doğru bir şekilde belirtiyor ancak hangi parametrelerin test edildiği sorusunu yanıtlamıyor. Bu nedenle kısmen doğru ve eksiktir.   \n",
       "\n",
       "   faithfulness  \\\n",
       "0           1.0   \n",
       "1           0.5   \n",
       "2           0.5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                            faithfulness_rationale  \\\n",
       "0                                                                                                                                                                                                  Cevap, RAG kalitesini ölçmek için kullanılan retrieval metriklerini (Recall@k, MRR, nDCG) doğrudan ve eksiksiz bir şekilde Bağlam [C1]'den almaktadır. Bağlam, cevabın ana noktalarını açıkça desteklemektedir.   \n",
       "1  Cevap, HITL'nin doğruluğu artırmak için kullanıldığı bilgisini doğrudan Bağlam [C1]'den almaktadır. Ancak, soru HITL'nin 'Document AI'da' ne işe yaradığını sormaktadır. Bağlam, Document AI'dan [C2] bahsetse de, HITL'nin bu özel bağlamda kullanıldığına dair açık bir bağlantı kurmamaktadır. Bu nedenle, cevabın ana noktası desteklenirken, sorunun spesifik kapsamı (Document AI) bağlamda tam olarak...   \n",
       "2                                                                                                      Cevap, Vertex AI Studio'nun amacını (prompt denemeleri ve model testleri) Bağlam [C1]'den doğru bir şekilde belirtmektedir. Ancak, sorunun ikinci kısmı olan 'hangi parametreler test edilir?' sorusunu yanıtlamamıştır, oysa bu bilgi de Bağlam [C1]'de mevcuttur (temperature, top-p, max_output_tokens).   \n",
       "\n",
       "    ctx_doc_ids  \n",
       "0  [D3, D2, D1]  \n",
       "1  [D2, D2, D3]  \n",
       "2  [D1, D3, D2]  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_ctx = 3  # judge'a verilecek context parçası sayısı (top-k)\n",
    "\n",
    "rows = []\n",
    "for _, g in df_golden.iterrows():\n",
    "    qid = g[\"qid\"]\n",
    "    q = g[\"query\"]\n",
    "\n",
    "    top = bm25_search(bm25_i, df_chunks_improved, q, k=k_ctx)\n",
    "    contexts = top[\"text\"].tolist()\n",
    "\n",
    "    ans = rag_answers.get(qid)\n",
    "    if (ans is None or not str(ans).strip()) and use_golden_if_missing:\n",
    "        ans = g[\"answer\"]\n",
    "\n",
    "    rel = judge_relevance_tr(q, ans)\n",
    "    fai = judge_faithfulness_tr(q, ans, contexts)\n",
    "\n",
    "    rows.append({\n",
    "        \"qid\": qid,\n",
    "        \"answer_relevance\": rel[\"score\"],\n",
    "        \"relevance_rationale\": rel[\"rationale\"],\n",
    "        \"faithfulness\": fai[\"score\"],\n",
    "        \"faithfulness_rationale\": fai[\"rationale\"],\n",
    "        \"ctx_doc_ids\": top[\"doc_id\"].tolist(),\n",
    "    })\n",
    "\n",
    "df_judge = pd.DataFrame(rows)\n",
    "df_judge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d7e22cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>answer_relevance</th>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faithfulness</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean_score\n",
       "answer_relevance    0.833333\n",
       "faithfulness        0.666667"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_judge[[\"answer_relevance\",\"faithfulness\"]].mean().to_frame(\"mean_score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vertex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
